{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "02_Validation-Basics.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohd-faizy/CAREER-TRACK-Machine-Learning-Scientist-with-Python/blob/main/02_Validation_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItfjD-Nq_RFa"
      },
      "source": [
        "--- \n",
        "<strong> \n",
        "    <h1 align='center'>Creating train-test & validation datasets</h1> \n",
        "</strong>\n",
        "\n",
        "---\n",
        "\n",
        "This chapter focuses on the basics of model validation. From splitting data into training, validation, and testing datasets, to creating an understanding of the bias-variance tradeoff, we build the foundation for the techniques of K-Fold and Leave-One-Out validation practiced in chapter three."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBwrq_tJ_b_B",
        "outputId": "b9dca8dd-6edc-41f9-b06e-c9a776d87441"
      },
      "source": [
        "!git clone https://github.com/mohd-faizy/CAREER-TRACK-Machine-Learning-Scientist-with-Python.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CAREER-TRACK-Machine-Learning-Scientist-with-Python'...\n",
            "remote: Enumerating objects: 657, done.\u001b[K\n",
            "remote: Counting objects: 100% (328/328), done.\u001b[K\n",
            "remote: Compressing objects: 100% (293/293), done.\u001b[K\n",
            "remote: Total 657 (delta 76), reused 269 (delta 33), pack-reused 329\u001b[K\n",
            "Receiving objects: 100% (657/657), 201.13 MiB | 33.49 MiB/s, done.\n",
            "Resolving deltas: 100% (202/202), done.\n",
            "Checking out files: 100% (311/311), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV6e3XLr_i-Y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "#plt.style.use('ggplot')\n",
        "#sns.set_theme()\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuNcMmq4_klc",
        "outputId": "d636d6d9-466f-4d41-e043-492f33dcb02f"
      },
      "source": [
        "os.chdir('/content/CAREER-TRACK-Machine-Learning-Scientist-with-Python/10_Model_Validation_in_Python/_dataset')\n",
        "cwd = os.getcwd()\n",
        "print('Curent working directory is ', cwd)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Curent working directory is  /content/CAREER-TRACK-Machine-Learning-Scientist-with-Python/10_Model_Validation_in_Python/_dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5sVNREN_xi_",
        "outputId": "8ae8fe31-7c66-4b61-80f3-82c41a308c1e"
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "candy-data.csv  sports.csv  tic-tac-toe.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cip00ONoBY31"
      },
      "source": [
        "## Creating train,test, and validation datasets\n",
        "- Traditional __`train_test_split`__\n",
        "    - Seen data (***used for training***)\n",
        "    - Unseen data (***unavailable for training***)\n",
        "\n",
        "We define a holdout dataset as any data **that is not used for training** and **is only used to assess model performance**.\n",
        "\n",
        "<p align='center'>\n",
        "\t<a href='#'><img src='https://miro.medium.com/max/1466/1*aNPC1ifHN2WydKHyEZYENg.png'>\n",
        "    </a>\n",
        "</p>\n",
        "\n",
        "$$\n",
        "\\begin{array}{ll}\n",
        "\\text { Dataset } & \\text { Definition } \\\\\n",
        "\\text { Train } & \\text { The sample of data used when fitting models } \\\\\n",
        "\\text { Test (holdout sample) } & \\text { The sample of data used to assess model performance }\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "**Ratio Examples**\n",
        "- $80:20$\n",
        "- $90:10$ (used when we have little data)\n",
        "- $70:30$ (used when model is computationally expensive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7xxGnvyBY31"
      },
      "source": [
        "### Create **one holdout** set\n",
        "\n",
        "Your boss has asked you to create a simple random forest model on the `tic_tac_toe` dataset. She doesn't want you to spend much time selecting parameters; rather she wants to know how well the model will perform on future data. For future Tic-Tac-Toe games, it would be nice to know if your model can predict which player will win."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLvpPkR8BY32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "27b04b23-06ec-48dc-b51a-9a397a5b496f"
      },
      "source": [
        "tic_tac_toe = pd.read_csv('tic-tac-toe.csv')\n",
        "tic_tac_toe.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Top-Left</th>\n",
              "      <th>Top-Middle</th>\n",
              "      <th>Top-Right</th>\n",
              "      <th>Middle-Left</th>\n",
              "      <th>Middle-Middle</th>\n",
              "      <th>Middle-Right</th>\n",
              "      <th>Bottom-Left</th>\n",
              "      <th>Bottom-Middle</th>\n",
              "      <th>Bottom-Right</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>b</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Top-Left Top-Middle Top-Right  ... Bottom-Middle Bottom-Right     Class\n",
              "0        x          x         x  ...             o            o  positive\n",
              "1        x          x         x  ...             x            o  positive\n",
              "2        x          x         x  ...             o            x  positive\n",
              "3        x          x         x  ...             b            b  positive\n",
              "4        x          x         x  ...             o            b  positive\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNkXqKSo291e"
      },
      "source": [
        "**Parameters**\n",
        "- `test_size`\n",
        "- `train_size`\n",
        "- `random_state`\n",
        "\n",
        "`test_size` takes either a float or an integer and specifies how big the test set should be.\n",
        "\n",
        "If `test_size` is blank, you can instead use `train_size` to set the size of the training set.\n",
        "\n",
        " And finally, `random_state` allows for setting the model seed and helps maintain reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P10ynB4iBY33"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create dummy variables using pandas\n",
        "# The first nine columns of tic_tac_toe can be used for training,\n",
        "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
        "# while the 10th column contains the response values\n",
        "y = tic_tac_toe.iloc[:, 9]\n",
        "\n",
        "# Create training and testing datasets, Use 10% for the test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1111)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "9zw2lnknd6jN",
        "outputId": "f610b777-024d-4416-de38-cb779d954442"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Top-Left_b</th>\n",
              "      <th>Top-Left_o</th>\n",
              "      <th>Top-Left_x</th>\n",
              "      <th>Top-Middle_b</th>\n",
              "      <th>Top-Middle_o</th>\n",
              "      <th>Top-Middle_x</th>\n",
              "      <th>Top-Right_b</th>\n",
              "      <th>Top-Right_o</th>\n",
              "      <th>Top-Right_x</th>\n",
              "      <th>Middle-Left_b</th>\n",
              "      <th>Middle-Left_o</th>\n",
              "      <th>Middle-Left_x</th>\n",
              "      <th>Middle-Middle_b</th>\n",
              "      <th>Middle-Middle_o</th>\n",
              "      <th>Middle-Middle_x</th>\n",
              "      <th>Middle-Right_b</th>\n",
              "      <th>Middle-Right_o</th>\n",
              "      <th>Middle-Right_x</th>\n",
              "      <th>Bottom-Left_b</th>\n",
              "      <th>Bottom-Left_o</th>\n",
              "      <th>Bottom-Left_x</th>\n",
              "      <th>Bottom-Middle_b</th>\n",
              "      <th>Bottom-Middle_o</th>\n",
              "      <th>Bottom-Middle_x</th>\n",
              "      <th>Bottom-Right_b</th>\n",
              "      <th>Bottom-Right_o</th>\n",
              "      <th>Bottom-Right_x</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Top-Left_b  Top-Left_o  ...  Bottom-Right_o  Bottom-Right_x\n",
              "0           0           0  ...               1               0\n",
              "1           0           0  ...               1               0\n",
              "2           0           0  ...               0               1\n",
              "3           0           0  ...               0               0\n",
              "4           0           0  ...               0               0\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAQIrTx1d8Th",
        "outputId": "3c94b00b-e58f-4f2f-f7e7-5b6274a9a1a2"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    positive\n",
              "1    positive\n",
              "2    positive\n",
              "3    positive\n",
              "4    positive\n",
              "Name: Class, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKORbekdBY35"
      },
      "source": [
        "### Create **two holdout** sets\n",
        "\n",
        "You recently created a simple random forest model to predict Tic-Tac-Toe game wins for your boss, and at her request, you did not do any parameter tuning. Unfortunately, the overall model accuracy was too low for her standards. This time around, she has asked you to focus on model performance.\n",
        "\n",
        "Before you start testing different models and parameter sets, you will need to split the data into training, validation, and testing datasets. Remember that after splitting the data into training and testing datasets, the validation dataset is created by splitting the training dataset.\n",
        "\n",
        "<p align='center'>\n",
        "\t<a href='#'><img src='https://i.stack.imgur.com/pXAfX.png' height=380, width= 600>\n",
        "    </a>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XevDnIMfBY36"
      },
      "source": [
        "# Create temporary training and Final Testing datasets\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y,\n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=1111)\n",
        "\n",
        "# Create the final training and validation datasets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, \n",
        "                                                  test_size=0.25,\n",
        "                                                  random_state=1111)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAmP1FVvBY37"
      },
      "source": [
        "You now have training, validation, and testing datasets, but do you know when you need both validation and testing datasets?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FBV7r_f-S-d"
      },
      "source": [
        "It is important to understand when you would use three datasets (training, validation, and testing) instead of two (training and testing). There is no point in creating an additional dataset split if you are not going to use it.\n",
        "\n",
        "**Validation set** is used for tuning the parameters of a model.\n",
        "\n",
        "---\n",
        "\n",
        "${\\text{When should you consider using training, validation, and testing datasets?}}$\n",
        "\n",
        "> **When testing parameters, tuning hyper-parameters, or Anytime we are evaluating model performance repeatedly we need to create training, validation, and testing datasets.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5oEAK1jBY37"
      },
      "source": [
        "## **Accuracy metrics**: Regression Models\n",
        "\n",
        "- **Mean absolute error (MAE)**\n",
        "$$ \\text{MAE} = \\frac{\\sum_{i=1}^{n} \\vert y_i - \\hat{y_i} \\vert}{n} $$\n",
        "    - **Simplest and most intuitive metric**\n",
        "    - **Treats all points equally**\n",
        "    - **Not sensitive to outlier** \n",
        "\n",
        "    This metric **treats all points equally** and is **not sensitive to outliers**. When dealing with applications **where we don't want large errors to have a major impact**, the mean absolute error can be used. An **example** could be predicting your car's monthly gas bill, when an outlier may have been caused by a one-time road trip.\n",
        "\n",
        "\n",
        "- **Mean squared error (MSE)**\n",
        "$$ \\text{MSE} = \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}{n} $$\n",
        "    - **Most widely used regression metric**\n",
        "    - **Allows outlier errors to contribute more to the overall error**\n",
        "    - **Random family road trips could lead to large errors in predictions**\n",
        "\n",
        "    Mean Squared Error(MSE) is the most **widely used regression error metric for regression models**. It is calculated similarly to the mean absolute error, but this time **we square the difference term**. **The MSE allows larger errors to have a larger impact on the model**. Using the previous car example, if you knew once a year you might go on a road trip, you might expect to occasionally have a large error and would want your model to pick up on these trips.\n",
        "\n",
        "\n",
        "- **MAE vs. MSE**\n",
        "    - **Accuracy metrics are always application apecific**\n",
        "    - **MAE and MSE error terms are in different units and should not be compared**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXRsXbylBY38"
      },
      "source": [
        "### **Mean Absolute Error**\n",
        "Communicating modeling results can be difficult. However, most clients understand that on average, a predictive model was off by some number. This makes explaining the mean absolute error easy. For example, when predicting the number of wins for a basketball team, if you predict 42, and they end up with 40, you can easily explain that the error was two wins.\n",
        "\n",
        "In this exercise, you are interviewing for a new position and are provided with two arrays. `y_test`, the true number of wins for all 30 NBA teams in 2017 and `predictions`, which contains a prediction for each team. To test your understanding, you are asked to both manually calculate the MAE and use `sklearn`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifYmwOzCBY39"
      },
      "source": [
        "y_test = np.array([53, 51, 51, 49, 43, 42, 42, 41, 41,\n",
        "                   37, 36, 31, 29, 28, 20, 67, 61, 55,\n",
        "                   51, 51, 47, 43, 41, 40, 34, 33, 32,\n",
        "                   31, 26, 24])\n",
        "\n",
        "y_pred = np.array([60, 62, 42, 42, 30, 50, 52, 42, 44,\n",
        "                   35, 30, 30, 35, 40, 15, 72, 58, 60, \n",
        "                   40, 42, 45, 46, 40, 35, 25, 40, 20, \n",
        "                   34, 25, 24])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKqUU_zUBY3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e65f09-70fa-4d1c-c4bd-7dfd832fdadb"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "# Manually calculate the MAE\n",
        "n = len(y_pred)\n",
        "mae_one = sum(abs(y_test - y_pred)) / n\n",
        "print('With a manual calculation, the error is {}'.format(mae_one))\n",
        "\n",
        "# Use scikit-learn to calculate the MAE\n",
        "mae_two = mae(y_test, y_pred)\n",
        "print('Using scikit-learn, the error is {}'.format(mae_two))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With a manual calculation, the error is 5.9\n",
            "Using scikit-learn, the error is 5.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrxRVcBjBY3_"
      },
      "source": [
        "These predictions were about six wins off on average. This isn't too bad considering NBA teams play 82 games a year. Let's see how these errors would look if you used the mean squared error instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrfdpYRwBY4A"
      },
      "source": [
        "### **Mean Squared Error**\n",
        "Let's focus on the 2017 NBA predictions again. Every year, there are at least a couple of NBA teams that win way more games than expected. If you use the MAE, this accuracy metric does not reflect the bad predictions as much as if you use the MSE. Squaring the large errors from bad predictions will make the accuracy look worse.\n",
        "\n",
        "In this example, NBA executives want to better predict team wins. You will use the mean squared error to calculate the prediction error. The actual wins are loaded as `y_test` and the `predictions` as predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VFXmV3PBY4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9537ef0-87bd-49bc-bcfd-c675be046686"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "n = len(y_pred)\n",
        "# Finish the manual calculation of the MSE\n",
        "mse_one = sum((y_test - y_pred) ** 2) / n\n",
        "print('With a manual calculation, the error is {}'.format(mse_one))\n",
        "\n",
        "# Use the scikit-learn function to calculate MSE\n",
        "mse_two = mse(y_test, y_pred)\n",
        "print('Using scikit-learn, the error is {}'.format(mse_two))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With a manual calculation, the error is 49.1\n",
            "Using scikit-learn, the error is 49.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXhuo2YGBY4B"
      },
      "source": [
        "If you run any additional models, you will try to beat an MSE of 49.1, which is the average squared error of using your model. Although the MSE is not as interpretable as the MAE, **it will help us select a model that has fewer 'large' errors**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajulJcTaBY4C"
      },
      "source": [
        "### Performance on data subsets\n",
        "In professional basketball, there are two conferences, the East and the West. Coaches and fans often only care about how teams in their own conference will do this year.\n",
        "\n",
        "You have been working on an NBA prediction model and would like to determine if the predictions were better for the East or West conference. You added a third array to your data called `labels`, which contains an \"E\" for the East teams, and a \"W\" for the West. `y_test` and `predictions` have again been loaded for your use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJa0V1x4BY4C"
      },
      "source": [
        "labels= np.array(['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E','E', 'E',\n",
        "                  'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W','W', 'W', 'W', 'W'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpbqCT2dBY4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471ce9e9-b09a-4a08-e7a7-f1cc21861a2c"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "# Find the East conference teams\n",
        "east_teams = labels == 'E'\n",
        "\n",
        "# Create arrays for the true and predicted values\n",
        "true_east = y_test[east_teams]\n",
        "preds_east = y_pred[east_teams]\n",
        "\n",
        "west_teams = labels == 'W'\n",
        "true_west = y_test[west_teams]\n",
        "preds_west = y_pred[west_teams]\n",
        "\n",
        "# Print the accuracy metrics\n",
        "print('The MAE for East teams is {}'.format(mae(true_east, preds_east)))\n",
        "\n",
        "# Print the west accuracy\n",
        "print('The MAE for West teams is {}'.format(mae(true_west, preds_west)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The MAE for East teams is 6.733333333333333\n",
            "The MAE for West teams is 5.066666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beY5EnxxBY4E"
      },
      "source": [
        " It looks like the Western conference predictions were about two games better on average. Over the past few seasons, the Western teams have generally won the same number of games as the experts have predicted. Teams in the East are just not as predictable as those in the West."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvleV3hcBY4E"
      },
      "source": [
        "## **Classification metrics**\n",
        "\n",
        "- **Types:**\n",
        "    - ***Precision***\n",
        "    - ***Recall*** (also called sensitivity)\n",
        "    - ***Accuracy***\n",
        "    - ***Specificity***\n",
        "    - ***F1-score*** and its variations\n",
        "\n",
        "- **Confusion Matrix**\n",
        "    - **True Positive:** Predict/Actual are both 1\n",
        "    - **True Negative:** Predict/Actual are both 0\n",
        "    - **False Positive:** Predicted 1, actual 0\n",
        "    - **False Negative:** Predicted 0, actual 1\n",
        "\n",
        "<p align='center'>\n",
        "\t<a href='#'><img src='https://miro.medium.com/max/712/1*Z54JgbS4DUwWSknhDCvNTQ.png'>\n",
        "    </a>\n",
        "</p>\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpacMkQVBY4F"
      },
      "source": [
        "### Confusion matrices\n",
        "Confusion matrices are a great way to start exploring your model's accuracy. They provide the values needed to calculate a wide range of metrics, including sensitivity, specificity, and the F1-score.\n",
        "\n",
        "You have built a classification model to predict if a person has a broken arm based on an X-ray image. On the testing set, you have the following confusion matrix:\n",
        "\n",
        "$$\n",
        "\\begin{array}{lll} \n",
        "& \\text { Prediction: } 0 & \\text { Prediction: } 1 \\\\\n",
        "\\hline \\text { Actual: } 0 & 324(\\mathrm{TN}) & 15(\\mathrm{FP}) \\\\\n",
        "\\text { Actual: } 1 & 123(\\mathrm{FN}) & 491(\\mathrm{TP})\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR8LykNNBY4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac68f05e-14a9-4bf9-d40d-365d008649e2"
      },
      "source": [
        "# Calculate and print the accuracy\n",
        "accuracy = (324 + 491) / (953)\n",
        "print(\"The overall accuracy is {0: 0.2f}\".format(accuracy))\n",
        "\n",
        "# Calculate and print the precision\n",
        "precision = (491) / (15 + 491)\n",
        "print(\"The precision is {0: 0.2f}\".format(precision))\n",
        "\n",
        "# Calculate and print the recall\n",
        "recall = (491) / (123 + 491)\n",
        "print(\"The recall is {0: 0.2f}\".format(recall))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The overall accuracy is  0.86\n",
            "The precision is  0.97\n",
            "The recall is  0.80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAy3GwMWBY4G"
      },
      "source": [
        "In this case, a true positive is a picture of an actual broken arm that was also predicted to be broken. Doctors are okay with a few additional false positives (predicted broken, not actually broken), as long as you don't miss anyone who needs immediate medical attention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZEBI2YKBY4H"
      },
      "source": [
        "\n",
        "### Confusion matrices, again\n",
        "Creating a confusion matrix in Python is simple. The biggest challenge will be making sure you understand the orientation of the matrix. This exercise makes sure you understand the `sklearn` implementation of confusion matrices. Here, you have created a random forest model using the `tic_tac_toe` dataset `rfc` to predict outcomes of 0 (loss) or 1 (a win) for Player One.\n",
        "\n",
        "Note: If you read about confusion matrices on another website or for another programming language, the values might be reversed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3PiGJcKBY4I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "0e806a68-b7fd-4392-b664-c81dd25873f7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tic_tac_toe = pd.read_csv('tic-tac-toe.csv')\n",
        "\n",
        "# Create dummy variables using pandas\n",
        "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
        "y = tic_tac_toe.iloc[:, 9]\n",
        "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "# Create training and testing datasets, Use 10% for the test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1111)\n",
        "\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=500, random_state=1111)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Create predictions\n",
        "test_predictions = rfc.predict(X_test)\n",
        "\n",
        "# Create and print the confusion matrix\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "\n",
        "# Print the true positives (actual 1s that were predicted 1s)\n",
        "print('The number of true positives is: {}'.format(cm[1, 1]))\n",
        "\n",
        "print('Confusion Matrix')\n",
        "col  = ['Act Neg', 'Act Pos']\n",
        "index = ['Pred Neg', 'Pred Pos']\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "df_cm = pd.DataFrame(cm, col, index)\n",
        "sns.heatmap(df_cm, cmap='Blues', annot=True, fmt=\"d\")\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of true positives is: 66\n",
            "Confusion Matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD1CAYAAABEDd6nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXsklEQVR4nO3de7xVdZ3/8df7nAM/BIxLyomQBAU1x1IsFVMU5aeZ4UhqKGYxI6NmZlreqJya+uWMpjPlI5vGCxlddLxfUgcvBEn9/IkjmKhYKt4gOKiBKaLcPr8/9qLO4Dlnr81e++y113k/eazH2Wvtvb/7sx+Pzft8z3d993cpIjAzs+JoqncBZmaWLQe7mVnBONjNzArGwW5mVjAOdjOzgnGwm5kVTEstGr107hLPobTMfX7siHqXYAW0bZ8mZdXWNmO+mDr71i68IrPX3VJNgt3MrEdSPgZBHOxmZllRzTrhFXGwm5llxT12M7OCcY/dzKxgmprrXQHgYDczy46HYszMCsZDMWZmBeMeu5lZwbjHbmZWMO6xm5kVjGfFmJkVjHvsZmYFk916YlVxsJuZZcU9djOzgsnJrJh8/HoxMyuCpub0WwckDZR0s6SnJS2WtL+kwZLul/RM8nNQ2TIyf2NmZj2VmtJvHbscmBURuwF7AouB6cDsiBgNzE72u+RgNzPLipR+e9dTNQA4CJgBEBHrImI1cDQwM3nYTGBSuTIc7GZmWamuxz4SeAW4VtJCSddI6ge0RsTy5DErgNZyZTjYzcyyUkWPndJklr2BH0XEGGANWwy7REQAZa+r6mA3M8tKdT32pcDSiHg42b+ZUtC3SRoKkPxcWa4MB7uZWVaqmBUTESuAlyXtmhyaADwF3AlMTY5NBe4oV4bnsZuZZaX6LyidCfxCUm9gCfD3lDrgN0qaBrwITC7XiIPdzCwrVX5BKSIeAz7awV0TKmnHwW5mlhUvKWBmVjA5WVLAwW5mlhX32M3MikVNDnYzs0KRh2LMzAomH7nuYDczy4p77GZmBeNgNzMrmCafPDUzK5h8dNgd7GZmWfFQjJlZwTjYzcwKxsFuZlYwDnYzs4JRk4PdzKxQ3GM3MysYB7uZWdHkI9cd7GZmWXGP3cysYBzsZmYF47VizMyKJh8ddge7mVlWPBRjZlYwDnYzs4KpNtglvQC8AWwENkTERyUNBm4ARgAvAJMjYlVX7TjYu8mbf3qFX197GWvfWAWI3cZ9gj0mTOK1l5/jN7/4ARvXr6epqZmPnXgGQ0buWu9yrUGtWLGcb359On/602sI+NRxk5nymc/Vu6weI6MlBQ6JiFfb7U8HZkfExZKmJ/sXdNWAg72bNDU3s9+nT2G7D4xi3dtvcftFX2LYB8cw/5YZ7D3xMwzfYx9eXjSf+bfOYOI53613udagWpqb+fK557PbB/+GNWvW8NkTjmW/sR9jp51H1bu0HqFGQzFHA+OT2zOBuVQb7JKO6eDw68CiiFhZWX09V98Bg+k7YDAAvfv0ZeDQ4axZ/RpIrFv7FgDr1r5FvwHvrWeZ1uC2234I220/BIB+/foxYqedWbmyzcHeTTII9gDukxTAlRFxFdAaEcuT+1cAreUaSdNjnwbsD8xJ9scDjwIjJX07In5WaeU93RuvtvHaS88xZOSujJ18GrMuv5D5t1xDRHDU+f9a7/KsIP64bBm/f3oxe3xoz3qX0mNkEOwHRsQySUOA+yU93f7OiIgk9LuUZjZ9C/DBiDg2Io4Fdqf0W2U/yvw5YO+2/u21PHDldxg7+TR6b9OPxb++m7GTT2XKxT9j7KdPZd5Pv1/vEq0A3nprDeef8yXOOW86/fv3r3c5PYcq2DoQEcuSnyuB24B9gTZJQwGSn2VHStIE+/CIaGu3vzI59idgfYrnW2LTxg08cOV3GLXvIYzc+wAAnnnoAUaMKd0e+ZFxvPLC7+tZohXAhvXrOf8rZ3HEkUdx6P8+vN7l9CiSUm8dPLefpG033wYOB54A7gSmJg+bCtxRro40QzFzJd0F3JTsH5cc6wesTvF8AyKCB3/6fQa+bzgfOuyvpy36Dnwvy/+wiPfv+mH++PRjvGfIsDpWaY0uIvj2P13IyJ124qTP/V29y+lxmqqbFdMK3JaEfgtwXUTMkvQIcKOkacCLwORyDaUJ9jOAY4ADk/2ZwC0REcAhW1F8j9T23JM8+/9mM2jYCG79P2cAsM+kqYz77Jd46IYriU0baW7pzbiTvlTnSq2R/W7hAu65605Gjd6FEyd/CoAvnHk2B447uM6V9QzVjLFHxBLgXSdEIuI1YEJFdZTyucyDpB2B0RHxgKS+QHNEvNHZ4y+du6R8o2YV+vzYEfUuwQpo2z7ZXc9ul/Nnpc6+P3z3iJp9TbXsGLukU4CbgSuTQ8OA22tVkJlZo6pmjD1LaU6engEcAPwZICKeAYbUsigzs0Ykpd9qKc0Y+zsRsW7zbxhJLZSmO5qZWTtVnjzNTJpg/7WkrwHbSDoM+ALwy9qWZWbWePIS7GmGYqYDrwCLgNOAe4ALa1mUmVkjapihmIjYBFydbGZm1oncr8cuaQ6dj6VHRFQ0r9LMrOhyH+zAuR0cGwucT4q1CszMepqc5HrnwR4Rj26+Lelg4B+BPsDnI+K/uqE2M7OGkpeTp12OsUv6OKUTpe8AF0XEnK4eb2bWk+V+KCZZeGZ74FLgoeTY3pvvj4gFNa/OzKyB5CTXu+yxrwHepLSa47H8zxWEAzi0hnWZmTWc3PfYI2J8N9ZhZtbwcpLrvpi1mVlWct9jNzOzyjTErBgzM0svJx32VOuxz05zzMysp8vLeuxdTXfsA/QFtpM0iL/OinkPpYttmJlZO3npsXc1FHMacDbwfuBR/hrsfwauqHFdZmYNJ/cnTyPicuBySWdGxA+6sSYzs4aUl2BPsx77JkkDN+9IGiTpCzWsycysITU1KfVW0zpSPOaUiFi9eSciVgGn1K4kM7PG1DAX2gCaJSkiolS4moHetS3LzKzxNNJQzCzgBkkTJE0Ark+OmZlZO1n02CU1S1oo6a5kf6SkhyU9K+kGSWU71mmC/QLgV8DpyTYbOC/NmzQz60mapNRbF84CFrfbvwT4XkSMAlYB08rWUe4BEbEpIv4jIo6LiOOApwDPkjEz20K1J08l7QB8Ergm2RellXRvTh4yE5hUro5USwpIGgNMASYDzwO3pnmemVlPksFkl+9Tuvzotsn+e4HVEbEh2V9Kii+IdvXN010ohfkU4FXgBkARcUgVRZuZFVY1J08lTQRWRsSjksZXU0dXPfangXnAxIh4NnnhL1fzYmZmRVblpJgDgL+VdCSl60u/B7gcGCipJem17wAsK9dQV2PsxwDLgTmSrk5mxORjLo+ZWQ6pgn9bioivRsQOETECOAH4VUR8BphD6Up2AFOBO8rV0WmwR8TtEXECsFvS8NnAEEk/knR4pW/YzKzompR+q8AFwFckPUtpzH1GuSeUPXkaEWuA64DrklUeP5280H0VlWZmVnBZLRUQEXOBucntJcC+lTy/ogttJMsJXJVsZmbWTpn56d3GV1AyM8tITnLdwW5mlpW8rBXjYDczy0hOct3BbmaWleacJLuD3cwsIx6KMTMrmBpfGCk1B7uZWUbcYzczK5ic5LqD3cwsK+6xm5kVTHNOBtkd7GZmGclHrDvYzcwy47VizMwKJie57mA3M8uKT56amRVMTnLdwW5mlpVCz4o588CdatGs9XCD9vlivUuwAlq78IrM2vJQjJlZwXR6Eelu5mA3M8uIe+xmZgWTkyF2B7uZWVYKffLUzKwnykmuO9jNzLKSkyH23JzENTNreE1S6m1LkvpImi/pd5KelPSt5PhISQ9LelbSDZJ6l62jBu/NzKxHaqpg68A7wKERsSewF3CEpLHAJcD3ImIUsAqYlqYOMzPLgJR+21KUvJns9kq2AA4Fbk6OzwQmlavDY+xmZhmpdlaMpGbgUWAU8EPgOWB1RGxIHrIUGFauHQe7mVlGqp0VExEbgb0kDQRuA3bbmnYc7GZmGcnqQhsRsVrSHGB/YKCklqTXvgOwrGwdmVRhZmZVjbFL2j7pqSNpG+AwYDEwBzguedhU4I5ydbjHbmaWkSqHYoYCM5Nx9ibgxoi4S9JTwH9K+g6wEJhRriEHu5lZRlTF5awj4nFgTAfHlwD7VtKWg93MLCMtORncdrCbmWXEy/aamRWMFwEzMyuYnHTYHexmZlnJah57tRzsZmYZafbJUzOzYmmqYrpjlhzsZmYZyclIjIPdzCwrnhVjZlYwPnlqZlYwOcl1B7uZWVaqvdBGVhzsZmYZyclsRwe7mVlWvFaMmVnB5CPWHexmZpnxrBgzs4LJR6w72M3MMtPkWTFmZsXiWTFmZgXjWTFmZgWTj1h3sJuZZcY9djOzgml2sJuZFUs+Yj0/J3HNzBqelH5793M1XNIcSU9JelLSWcnxwZLul/RM8nNQuToc7GZmGWlCqbcObADOiYjdgbHAGZJ2B6YDsyNiNDA72S9Th5mZZaKaHntELI+IBcntN4DFwDDgaGBm8rCZwKRydXiM3cwsI8polF3SCGAM8DDQGhHLk7tWAK3lnu9gNzPLSBazYiT1B24Bzo6IP7efQhkRISnKteGhGDOzjFQzFFN6vnpRCvVfRMStyeE2SUOT+4cCK8vV4WA3M8tIlbNiBMwAFkfEv7W7605ganJ7KnBHuTo8FGNmlpEqx9gPAD4LLJL0WHLsa8DFwI2SpgEvApPLNeRgNzPLSDWr9kbEb+j8O04TKmnLwW5mlpG8XEHJY+x18tt5D/K3n/w4E484jBlXX1XvcqzBDei/DdddOo3Hbr2QhbdcyH4fHgnA6ScczGO3XsijN3+di846us5VFp8q+FdL7rHXwcaNG/nni77NlVdfS2trKycefxzjDzmUnUeNqndp1qAuO/847vu/T3HieTPo1dJM3z69Oeijo5k4/kPse/zFrFu/ge0H9a93mYWXkwsole+xSzpAUr/k9kmS/k3SjrUvrbieWPQ4w4fvyA7Dh9Ord2+OOPKTzJ0zu95lWYN6T/8+HLj3zvzktocAWL9hI6+/uZZTPz2Oy669n3XrNwDwyqo361lmj5CXHnuaoZgfAW9J2hM4B3gO+GlNqyq4lW1tvG/o+/6yP6S1lba2tjpWZI1sxPvfy6ur3uSqb53EQ9dfwL9/40T69unNqB2HcMCYnXnwp+dy3zVn8ZHdP1DvUguv2nnsWUkT7BsiIiitV3BFRPwQ2La2ZZlZWi0tzey123Cuvmke+0+5hLfWvsO5Jx9GS3MTgwf046DPXcbXvnc7P//uyfUutfBUwVZLaYL9DUlfpTS/8m5JTUCv2pZVbENaW1mxfMVf9le2tdHaWnb5B7MOLWtbxbKVq3nkiRcBuO2Bx9hrt+Esa1vN7bNL06H/+8kX2bQp2M7j7DXVLKXeailNsB8PvAOcHBErgB2AS2taVcH9zR4f4qWXXmDp0pdZv24ds+65m4MPObTeZVmDanvtDZauWMXoHYcAMH7fXXl6yQp+OfdxDt5nFwBGfWAIvXu18KrH2WsrJ132srNiImKFpF8A+0iaCMyPCI+xV6GlpYWvfv0bnH7qP7Bp00YmfepYRo0aXe+yrIF95ZKbuPaf/47eLc28sOxVTv3mz1mzdh1X/tNn+O+bvsa69Rv5h2/8rN5lFl6tT4qmpdLweRcPkCZT6qHPpfR7ZhxwXkTc3Nlz3t5A2dXHzCo1aJ8v1rsEK6C1C6/ILI3nL3k9dfbtu9OAmv0WSDOP/evAPhGxEkDS9sADQKfBbmbWE+Wjv54u2Js2h3riNfyNVTOzd8tJsqcJ9lmS7gWuT/aPB+6pXUlmZo0pL2vFpDl5ep6kY4ADk0NXRcRttS3LzKzx5CPWuwh2SaOBy4CdgUXAuRGxrLsKMzNrODlJ9q7Gyn8M3AUcCzwK/KBbKjIza1B5WSumq6GYbSPi6uT27yUtqGklZmYNLidD7F0Gex9JY/jrHxfbtN+PCAe9mVk7jRDsy4H2F1Rd0W4/AH8H3sysnbx887TTYI+IQ7qzEDOzRtcIPXYzM6tATnLdwW5mlpmcJLuD3cwsI3kZY09zzdN3XYyzo2NmZj1dk9JvNa2jszsk9ZE0GNhO0iBJg5NtBDCstmWZmTWgKi+0IenHklZKeqLdscGS7pf0TPJzULkyuuqxn0bpG6e7JT83b3cAV5Rr2Mysp8ngm6c/AY7Y4th0YHZEjAZmJ/td6mq64+XA5ZLOjAgvJ2BmVka10x0j4sFkVKS9o4Hxye2ZlC56dEFX7aRZV32TpIGbd5JhmS+kLdTMrKeo0SVPWyNieXJ7BdBa7glpgv2UiFi9eSciVgGnVFaXmVkPUOOLWUfpWqZlL7+XZrpjsyQlDSKpGei9dWWZmRVXjS600SZpaEQslzQUWFnuCWl67LOAGyRNkDSB0pWUZlVZqJlZ4dSow34nMDW5PZXSBJYupemxXwCcCpye7N8PXN35w83MeqgqO+ySrqd0onQ7SUuBbwIXAzdKmga8CEwu106aS+NtAv4j2ZA0jtJFN87Y2uLNzIqo2m+eRsSUTu6aUEk7qZYUSNZhn0LpN8XzwK2VvIiZWU+Q+9UdJe1CKcynAK8CNwDycr5mZh3LfbADTwPzgIkR8SyApC93S1VmZg2oERYBO4bSVZTmSLo6mRGTj6rNzHJISr/VUqfBHhG3R8QJlNaKmQOcDQyR9CNJh9e2LDOzxlPj7yelVnYee0SsiYjrIuIoYAdgIWXWKTAz64ly32PvSESsioirIqKiqTdmZj1DPvrsvoKSmVlGan0BjbQc7GZmGWmE6Y5mZlaBvEx3dLCbmWUlH7nuYDczy0pOct3BbmaWFY+xm5kVjHKS7A52M7OM5CPWHexmZpnJSYfdwW5mlhVPdzQzKxj32M3MCsbBbmZWMB6KMTMrGPfYzcwKJie57mA3M8tMTpLdwW5mlpG8jLFXdAUlMzPrXJPSbx2RdISk30t6VtL0ra5ja59oZmZbqOLKeJKagR8CnwB2B6ZI2n1rynCwm5llRBX868C+wLMRsSQi1gH/CRy9NXXUZIy9T0tOBpqsUNYuvKLeJZh1aZteVWXfMODldvtLgf22piH32M3MCsbBbmaWD8uA4e32d0iOVczBbmaWD48AoyWNlNQbOAG4c2sacrCnJGmjpMckPSHpJkl9q2jrJ5KO6+T4Mkn/K9nfTtILVZRtDaIbP1/PJ6+zQNL+1VVtWYqIDcAXgXuBxcCNEfHk1rTlYE9vbUTsFRF7AOuAz7e/U1JWJ6I3Aidn1JY1ju76fJ0XEXsB04ErM2rTMhIR90TELhGxc0RctLXtONi3zjxglKTxkuZJuhN4SlKzpEslPSLpcUmnAajkiuSLBw8AQ7po+/vAlzv6jyzpvHZtf6vd8X9M2v6NpOslnZvx+7XuVcvP12YPAqOS538l+UvhCUlnJ8f6Sbpb0u+S48fX6L1aDXhJgQolgfsJYFZyaG9gj4h4XtKpwOsRsU8ynPJbSfcBY4BdKX3poBV4CvhxJy/xEvAb4LPAL9u97uHAaEpzXQXcKekgYC1wLLAn0AtYADya3Tu27tQNn6/NjgIWSfoI8PeUptUJeFjSr4GdgD9GxCeTugZk+T6tthzs6W0j6bHk9jxgBvAxYH5EPJ8cPxz4cLvxzQGUwvgg4PqI2Aj8UdKvyrzWvwB3AHe3O3Z4si1M9vsnbW8L3BERbwNvS/ol1oi66/N1qaQLgVeAacAE4LaIWAMg6VZgHKVfLP8q6RLgroiYl9UbtdpzsKe3Nhmb/AuVFl9e0/4QcGZE3LvF446s5IUi4pnkP/nkLdr+l4j4H+Oim/90tobXXZ+v8yLi5nbPndDRgyLiD5L2Bo4EviNpdkR8u4LXsTryGHu27gVOl9QLQNIukvpRGs88PhkjHQockqKti4D2Y+X3AidL6p+0PUzSEOC3wFGS+iT3Tczw/Vi+ZPn52mweMElS36StTwHzJL0feCsifg5cSmlIyBqEe+zZugYYASxQqbv1CjAJuA04lNLY50vAQ+UaiognJS0g+Q8VEfdJ+iDwUNKTexM4KSIeSU6uPQ60AYuA1zN+X5YPmX2+NouIBZJ+Aszf/BoRsVDSxykN22wC1gOnZ/UmrPYUEfWuwaokqX9EvJnMfX4QODUiFtS7LjOrD/fYi+EqlZb37APMdKib9WzusZuZFYxPnpqZFYyD3cysYBzsZmYF42A3MysYB7uZWcE42M3MCub/A01400qG0n/FAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq8SpZ-7BY4K"
      },
      "source": [
        "Row 1, column 1 represents the number of actual 1s that were predicted 1s (the true positives). Always make sure you understand the orientation of the confusion matrix before you start using it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9EWzhI1BY4L"
      },
      "source": [
        "### Precision vs. recall\n",
        "The accuracy metrics you use to evaluate your model should always be based on the specific application. For this example, let's assume you are a really sore loser when it comes to playing Tic-Tac-Toe, but only when you are certain that you are going to win.\n",
        "\n",
        "Choose the most appropriate accuracy metric, either precision or recall, to complete this example. But remember, if you think you are going to win, you better win!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEOFP2NhBY4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723e788a-069f-4942-8b0e-32f929a2afb9"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# Create precision score based on the metric\n",
        "p_score = precision_score(y_test, y_pred)\n",
        "r_score = recall_score(y_test, y_pred)\n",
        "\n",
        "# Print the final result\n",
        "print('The precision value is {0:.2f}, The recall value is {1:.2f}'.format(p_score, r_score))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The precision value is 0.97, The recall value is 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRY70mFM0Mep"
      },
      "source": [
        "**Precision** is the correct metric here. Sore-losers can't stand losing when they are certain they will win! For that reason, our model needs to be as precise as possible. With a precision of only $79\\%$, you may need to try some other modeling techniques to improve this score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6QTyKtiBY4M"
      },
      "source": [
        "## **The bias-variance tradeoff**\n",
        "\n",
        "<p align='center'>\n",
        "\t<a href='#'><img src='https://www.researchgate.net/publication/335604816/figure/fig2/AS:799391489220609@1567601191401/Bias-variance-trade-off-in-machine-learning-This-figure-illustrates-the-trade-off.png' height=500>\n",
        "    </a>\n",
        "</p>\n",
        "\n",
        "- **Variance**\n",
        "    - Following the training data too closely\n",
        "    - Fails to generalize to the test data\n",
        "    - Low training error but high test error\n",
        "    - Occurs when models are overfit and have high complexity\n",
        "    - High variance makes over-fitting\n",
        "    \n",
        "- **Bias**\n",
        "    - Failing to find the relationship between the data and the response\n",
        "    - High training/test error\n",
        "    - Occurs when models are underfit\n",
        "    - High bias makes under-fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCi2c8MEBY4M"
      },
      "source": [
        "### Error due to under/over-fitting\n",
        "The candy dataset is prime for overfitting. With only 85 observations, if you use 20% for the testing dataset, you are losing a lot of vital data that could be used for modeling. Imagine the scenario where most of the chocolate candies ended up in the training data and very few in the holdout sample. Our model might only see that chocolate is a vital factor, but fail to find that other attributes are also important. In this exercise, you'll explore how using too many features (columns) in a random forest model can lead to overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6GxvWf-BY4N"
      },
      "source": [
        "candy = pd.read_csv('candy-data.csv')\n",
        "\n",
        "X = candy.drop(['competitorname', 'winpercent'], axis=1)\n",
        "y = candy['winpercent']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so0hYPwgBY4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeaf0011-8211-42fa-9031-881aa7887cab"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Update the rfr model\n",
        "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=2)\n",
        "\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = rfr.predict(X_train)\n",
        "y_pred_test = rfr.predict(X_test)\n",
        "\n",
        "# Print the training and test accuracy\n",
        "print('The training error is {0:.2f}'.format(mae(y_train, y_pred_train)))\n",
        "print('The testing error is {0:.2f}'.format(mae(y_test, y_pred_test)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training error is 3.88\n",
            "The testing error is 9.15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7qlri-CBY4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e1508e-fa0b-4c9d-88c8-1d902acf0b02"
      },
      "source": [
        "# Update the rfr model\n",
        "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=11)\n",
        "\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = rfr.predict(X_train)\n",
        "y_pred_test =rfr.predict(X_test)\n",
        "\n",
        "# Print the training and test accuracy\n",
        "print('The training error is {0:.2f}'.format(mae(y_train, y_pred_train)))\n",
        "print('The testing error is {0:.2f}'.format(mae(y_test, y_pred_test)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training error is 3.57\n",
            "The testing error is 10.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyH7pqN1BY4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97cd0be-6b88-42a2-c5ca-d857682c6db6"
      },
      "source": [
        "# Update the rfr model\n",
        "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=4)\n",
        "\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = rfr.predict(X_train)\n",
        "y_pred_test =rfr.predict(X_test)\n",
        "\n",
        "# Print the training and test accuracy\n",
        "print('The training error is {0:.2f}'.format(mae(y_train, y_pred_train)))\n",
        "print('The testing error is {0:.2f}'.format(mae(y_test, y_pred_test)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training error is 3.60\n",
            "The testing error is 8.79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8F9cFnuBY4P"
      },
      "source": [
        "### Am I underfitting?\n",
        "You are creating a random forest model to predict if you will win a future game of Tic-Tac-Toe. Using the `tic_tac_toe` dataset, you have created training and testing datasets, `X_train`, `X_test`, `y_train`, and `y_test`.\n",
        "\n",
        "You have decided to create a bunch of random forest models with varying amounts of trees (1, 2, 3, 4, 5, 10, 20, and 50). The more trees you use, the longer your random forest model will take to run. However, if you don't use enough trees, you risk underfitting. You have created a for loop to test your model at the different number of trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLZaPdi9BY4Q"
      },
      "source": [
        "# Create dummy variables using pandas\n",
        "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
        "y = tic_tac_toe.iloc[:, 9]\n",
        "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "# Create training and testing datasets, Use 10% for the test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c6fVrNXBY4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce057af0-5e9c-4829-9944-842844dd9c1e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_scores, train_scores = [], []\n",
        "for i in [1, 2, 3, 4, 5, 10, 20, 50]:\n",
        "    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n",
        "    rfc.fit(X_train, y_train)\n",
        "    \n",
        "    # Create predictions for the X_train and X_test datasets\n",
        "    train_predictions = rfc.predict(X_train)\n",
        "    test_predictions = rfc.predict(X_test)\n",
        "    \n",
        "    # Append the accuracy score for the test and train predictions\n",
        "    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n",
        "    test_scores.append(round(accuracy_score(y_test, test_predictions), 2))\n",
        "    \n",
        "# Print the train and test scores\n",
        "print(\"The training scores were: {}\".format(train_scores))\n",
        "print(\"The testing scores were: {}\".format(test_scores))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training scores were: [0.94, 0.93, 0.98, 0.97, 0.99, 1.0, 1.0, 1.0]\n",
            "The testing scores were: [0.83, 0.79, 0.89, 0.91, 0.91, 0.93, 0.97, 0.98]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ1H8SS0BY4S"
      },
      "source": [
        ">Notice that with only one tree, both the train and test scores are low. As you add more trees, both errors improve. Even at 50 trees, this still might not be enough. Every time you use more trees, you achieve higher accuracy. At some point though, more trees increase training time, but do not decrease testing error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cFt1ILfBY4S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "382e8832-23f6-49c1-fb14-18480f1793b3"
      },
      "source": [
        "x = [1, 2, 3, 4, 5, 10, 20, 50]\n",
        "tmp = pd.DataFrame({'x':x, 'training':train_scores, 'test':test_scores})\n",
        "tmp.set_index('x', inplace=True)\n",
        "tmp.plot(title='train/test score for n_estimators', figsize=(12,7))\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbLBupbN80Sa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6_unCI980LR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx0gK-Dq80BR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3K0SmYk_2ff"
      },
      "source": [
        "## __Connect with Me__ \n",
        "--- \n",
        "[<img align=\"left\" alt=\"codeSTACKr | Twitter\" width=\"40px\" src=\"https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/twitter.svg\" />][twitter] \n",
        "[<img align=\"left\" alt=\"codeSTACKr | LinkedIn\" width=\"40px\" src=\"https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/linkedin.svg\" />][linkedin] \n",
        "[<img align=\"left\" alt=\"codeSTACKr.com\" width=\"40px\" src=\"https://raw.githubusercontent.com/iconic/open-iconic/master/svg/globe.svg\" />][StackExchange AI] \n",
        "[twitter]: https://twitter.com/F4izy \n",
        "--- \n",
        "[linkedin]: https://www.linkedin.com/in/mohd-faizy/ \n",
        "--- \n",
        "[StackExchange AI]: https://mohd-faizy.github.io\n",
        "--- \n",
        "--- \n",
        "--- \n",
        "---"
      ]
    }
  ]
}