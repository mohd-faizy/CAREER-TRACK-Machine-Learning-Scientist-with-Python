{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "03_Cross-Validation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohd-faizy/CAREER-TRACK-Machine-Learning-Scientist-with-Python/blob/main/03_Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItfjD-Nq_RFa"
      },
      "source": [
        "--- \n",
        "<strong> \n",
        "    <h1 align='center'>Cross Validation</h1> \n",
        "</strong>\n",
        "\n",
        "---\n",
        "\n",
        "Holdout sets are a great start to model validation. However, using a single train and test set if often not enough. Cross-validation is considered the gold standard when it comes to validating model performance and is almost always used when tuning model hyper-parameters. This chapter focuses on performing cross-validation to validate model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBwrq_tJ_b_B",
        "outputId": "a09fd509-a6f1-4780-ef45-07a1ad3dbc6a"
      },
      "source": [
        "!git clone https://github.com/mohd-faizy/CAREER-TRACK-Machine-Learning-Scientist-with-Python.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CAREER-TRACK-Machine-Learning-Scientist-with-Python'...\n",
            "remote: Enumerating objects: 686, done.\u001b[K\n",
            "remote: Counting objects: 100% (357/357), done.\u001b[K\n",
            "remote: Compressing objects: 100% (317/317), done.\u001b[K\n",
            "remote: Total 686 (delta 91), reused 284 (delta 38), pack-reused 329\u001b[K\n",
            "Receiving objects: 100% (686/686), 202.35 MiB | 24.66 MiB/s, done.\n",
            "Resolving deltas: 100% (217/217), done.\n",
            "Checking out files: 100% (314/314), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV6e3XLr_i-Y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "#plt.style.use('ggplot')\n",
        "#sns.set_theme()\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuNcMmq4_klc",
        "outputId": "57f85037-9510-4579-8b7a-856ea91848a3"
      },
      "source": [
        "os.chdir('/content/CAREER-TRACK-Machine-Learning-Scientist-with-Python/10_Model_Validation_in_Python/_dataset')\n",
        "cwd = os.getcwd()\n",
        "print('Curent working directory is ', cwd)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Curent working directory is  /content/CAREER-TRACK-Machine-Learning-Scientist-with-Python/10_Model_Validation_in_Python/_dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5sVNREN_xi_",
        "outputId": "ab24d06f-bfd0-49f0-de8b-06b5de33f99f"
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "candy-data.csv  sports.csv  tic-tac-toe.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPr8AoyaIjSg"
      },
      "source": [
        "## The problems with holdout sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn0K5hq8IjSg"
      },
      "source": [
        "### Two samples\n",
        "After building several classification models based on the `tic_tac_toe` dataset, you realize that some models do not generalize as well as others. You have created training and testing splits just as you have been taught, so you are curious why your validation process is not working.\n",
        "\n",
        "After trying a different training, test split, you noticed differing accuracies for your machine learning model. Before getting too frustrated with the varying results, you have decided to see what else could be going on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c28DqK_IjSh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "5e986d2a-81e7-4c10-f509-cdbd9884dd12"
      },
      "source": [
        "tic_tac_toe = pd.read_csv('tic-tac-toe.csv')\n",
        "tic_tac_toe.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Top-Left</th>\n",
              "      <th>Top-Middle</th>\n",
              "      <th>Top-Right</th>\n",
              "      <th>Middle-Left</th>\n",
              "      <th>Middle-Middle</th>\n",
              "      <th>Middle-Right</th>\n",
              "      <th>Bottom-Left</th>\n",
              "      <th>Bottom-Middle</th>\n",
              "      <th>Bottom-Right</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>x</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>b</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>o</td>\n",
              "      <td>b</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Top-Left Top-Middle Top-Right  ... Bottom-Middle Bottom-Right     Class\n",
              "0        x          x         x  ...             o            o  positive\n",
              "1        x          x         x  ...             x            o  positive\n",
              "2        x          x         x  ...             o            x  positive\n",
              "3        x          x         x  ...             b            b  positive\n",
              "4        x          x         x  ...             o            b  positive\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Zk-YraIjSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4dc4b6-1118-404c-aa5c-cb1509123d35"
      },
      "source": [
        "# Create two different samples of 200 observations\n",
        "sample1 = tic_tac_toe.sample(n=200, random_state=1111)\n",
        "sample2 = tic_tac_toe.sample(n=200, random_state=1171)\n",
        "\n",
        "# Print the number of common observations\n",
        "print(len([index for index in sample1.index if index in sample2.index]))\n",
        "\n",
        "# Print the number of observations in the Class column for both samples\n",
        "print(sample1['Class'].value_counts())\n",
        "print(sample2['Class'].value_counts())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "positive    134\n",
            "negative     66\n",
            "Name: Class, dtype: int64\n",
            "positive    123\n",
            "negative     77\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ_SXvnVIjSk"
      },
      "source": [
        "> __Notice that there are a varying number of positive observations for both sample test sets. Sometimes creating a single test holdout sample is not enough to achieve the high levels of model validation you want. You need to use something more robust.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIcLQ8BcOwHI"
      },
      "source": [
        "**Potential problems with holdout samples:**\n",
        "\n",
        "- *Using different data splitting methods may lead to varying data in the final holdout samples.*\n",
        "\n",
        "- *we learned that our accuracy metric on this validation set may be misleading, or if we split this data differently, we might get different results.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHsu4o2BIjSl"
      },
      "source": [
        "## Cross-validation\n",
        "\n",
        "**Cross-validation** is a **resampling** procedure used to **evaluate** machine learning models on a **limited data sample**. The procedure has a single parameter called __k__ that refers to the number of groups that a given data sample is to be __split__ into. As such, the procedure is often called __k-fold cross-validation__.\n",
        "\n",
        "<p align='center'>\n",
        "    <a href='#'><img src='https://scikit-learn.org/stable/_images/grid_search_cross_validation.png'></a>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GkpLyOwIjSm"
      },
      "source": [
        "### scikit-learn's `KFold()`\n",
        "\n",
        "You just finished running a colleagues code that creates a **random forest model** and calculates an out-of-sample accuracy. You noticed that your colleague's code did not have a random state, and the errors you found were completely different than the errors your colleague reported.\n",
        "\n",
        "To get a better estimate for how accurate this **random forest model** will be on new data, you have decided **to generate some indices to use for KFold cross-validation**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rzbDm9rSNnN",
        "outputId": "29eb8075-ad3b-49fc-99bd-7689b4f3aa42"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error \n",
        "\n",
        "X = np.array(range(40))\n",
        "y = np.array([0]*20 + [1]*20)\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "splits = kf.split(X)\n",
        "\n",
        "for train_index, test_index in splits:\n",
        "    print(len(train_index), len(test_index))\n",
        "\n",
        "# Print one of the index sets:\n",
        "print(train_index, test_index)\n",
        "\n",
        "# Intensiating the model\n",
        "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
        "for train_index, val_index in splits:\n",
        "    # Setup the training and validation data\n",
        "    X_train, y_train = X[train_index], y[train_index]\n",
        "    X_val, y_val = X[val_index], y[val_index]\n",
        "    \n",
        "    # Fit the random forest model\n",
        "    rfc.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions, and print the accuracy\n",
        "    y_pred = rfc.predict(X_test)\n",
        "    print(\"Split accuracy: \",mean_squared_error(y_val, y_pred))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32 8\n",
            "32 8\n",
            "32 8\n",
            "32 8\n",
            "32 8\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31] [32 33 34 35 36 37 38 39]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqwLnrdQIjSn"
      },
      "source": [
        "candy = pd.read_csv('candy-data.csv')\n",
        "\n",
        "X = candy.drop(['competitorname', 'winpercent'], axis=1).to_numpy()\n",
        "y = candy['winpercent'].to_numpy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEQDGpuWIjSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993f1dad-5350-4cc4-9eb8-609398069385"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Use KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1111)\n",
        "\n",
        "# Create splits\n",
        "splits = kf.split(X)\n",
        "\n",
        "'''\n",
        "What dose splits contain?\n",
        "- The splits variable contains the training and validation \n",
        "  indices for the five different splits of X.\n",
        "\n",
        "'''\n",
        "# Print the number of indices\n",
        "for train_index, val_index in splits:\n",
        "    print(\"Number of training indices: %s\" % len(train_index))\n",
        "    print(\"Number of validation indices: %s\" % len(val_index))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n",
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n",
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n",
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n",
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlVWphkmIjSp"
      },
      "source": [
        "> **This dataset has 85 rows. You have created five splits - each containing 68 training and 17 validation indices. You can use these indices to complete 5-fold cross-validation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8CQremCIjSq"
      },
      "source": [
        "### Using `KFold` indices\n",
        "\n",
        "You have already created `splits`, which contains __indices__ for the candy-data dataset to complete __5-fold cross-validation__. To get a better estimate for how well a colleague's random forest model will perform on a new data, you want to run this model on the five different __training__ and __validation__ indices you just created.\n",
        "\n",
        "In this exercise, you will use these indices to check the accuracy of this model using the five different splits. A for loop has been provided to assist with this process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7zl8izRIjSq"
      },
      "source": [
        "# Create splits\n",
        "splits = kf.split(X)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV3g6ytQIjSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbb248b-bd5a-4df4-a690-6be1d5fb82fc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
        "\n",
        "# Access the training and validation indices of splits\n",
        "for train_index, val_index in splits:\n",
        "    # Setup the training and validation data\n",
        "    X_train, y_train = X[train_index], y[train_index]\n",
        "    X_val, y_val = X[val_index], y[val_index]\n",
        "    # Fit the random forest model\n",
        "    rfc.fit(X_train, y_train)\n",
        "    # Make predictions, and print the accuracy\n",
        "    predictions = rfc.predict(X_val)\n",
        "    print(\"Split accuracy: \" + str(mean_squared_error(y_val, predictions)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split accuracy: 151.5028145199104\n",
            "Split accuracy: 173.4624060357644\n",
            "Split accuracy: 132.7340977072911\n",
            "Split accuracy: 81.50364942339418\n",
            "Split accuracy: 217.17904656079338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdcmv4NUIjSs"
      },
      "source": [
        "> __`KFold()` is a great method for accessing individual indices when completing cross-validation. One drawback is needing a for loop to work through the indices though.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIUcdShnIjSt"
      },
      "source": [
        "## sklearn's `cross_val_score()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzzpBz1VIjSt"
      },
      "source": [
        "### scikit-learn's methods\n",
        "You have decided to build a regression model to predict the number of new employees your company will successfully hire next month. You open up a new Python script to get started, but you quickly realize that sklearn has a lot of different modules. Let's make sure you understand the names of the modules, the methods, and which module contains which method.\n",
        "\n",
        "Follow the instructions below to load in all of the necessary methods for completing cross-validation using sklearn. You will use modules:\n",
        "\n",
        "- metrics\n",
        "- model_selection\n",
        "- ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdX_8VHHIjSu"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, make_scorer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izg6_E5RIjSv"
      },
      "source": [
        "### Implement `cross_val_score()`\n",
        "\n",
        "Your company has created several new candies to sell, but they are not sure if they should release all five of them. To predict the popularity of these new candies, you have been asked to build a regression model using the candy dataset. Remember that the response value is a head-to-head win-percentage against other candies.\n",
        "\n",
        "Before you begin trying different regression models, you have decided to run cross-validation on a simple random forest model to get a baseline error to compare with any future results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etUhhMLqIjSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2fabd3-9903-4e73-b7e3-5f4ee60c00e5"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "\n",
        "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
        "mse = make_scorer(mean_squared_error)\n",
        "\n",
        "# Setup cross_val_score\n",
        "cv = cross_val_score(estimator=rfc,\n",
        "                     X=X_train,\n",
        "                     y=y_train,\n",
        "                     cv=10,\n",
        "                     scoring=mse)\n",
        "\n",
        "# Print the mean error\n",
        "print(cv.mean())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130.91371947185584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zigbe_2iIjSw"
      },
      "source": [
        "You now have a baseline score to build on. If you decide to build additional models or try new techniques, you should try to get an error lower than 155.56. Lower errors indicate that your popularity predictions are improving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNExdnolIjSw"
      },
      "source": [
        "## Leave-one-out-cross-validation (LOOCV)\n",
        "- **LOOCV**\n",
        "In **leave-one-out-cross-validation**, we are going to implement `KFold` cross-validation, where `k` is equal to `n`, the number of observations in the data. \n",
        "\n",
        "<p align='center'>\n",
        "    <a href='#'><img src='https://biol607.github.io/lectures/images/cv/loocv.png'></a>\n",
        "</p>\n",
        "\n",
        "- When to use LOOCV?\n",
        "    - The amount of **training data is limited**\n",
        "    - You want the absolute best error estimate for new data\n",
        "\n",
        "- Be cautious when:\n",
        "    - Computation resources are limited\n",
        "    - You have a lot of data\n",
        "    - You have a lot of parameters to test\n",
        "\n",
        "- if you are planning on testing a lot of different parameter sets. The best way to judge if this method is even possible is to run __KFold__ cross-validation with a large __K__, maybe $25$ or $50$, and gauge how long it would take you to actually run Leave-one-out-cross-validation with the __n-observations__ in your data.\n",
        "\n",
        "- We can find the __Number of observations__ by looking at the shape of the __X__ dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9s2wUqCIjSx"
      },
      "source": [
        "### Leave-one-out-cross-validation\n",
        "Let's assume your favorite candy is not in the candy dataset, and that you are interested in the popularity of this candy. Using 5-fold cross-validation will train on only 80% of the data at a time. The candy dataset only has 85 rows though, and leaving out 20% of the data could hinder our model. However, using leave-one-out-cross-validation allows us to make the most out of our limited dataset and will give you the best estimate for your favorite candy's popularity!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH5vmGWYoJlZ",
        "outputId": "ab32285e-0acb-41e5-bd41-c048aeedc62f"
      },
      "source": [
        "y.shape[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLRRCaQ2IjSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f8a7e1-2ea1-4157-9016-7fd48d7ed16d"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, make_scorer\n",
        "\n",
        "# Create scorer\n",
        "mae_scorer = make_scorer(mean_absolute_error)\n",
        "\n",
        "rfr = RandomForestRegressor(n_estimators=15, random_state=1111)\n",
        "\n",
        "# Implement LOOCV\n",
        "scores = cross_val_score(rfr, X=X, y=y, cv=y.shape[0], scoring=mae_scorer)\n",
        "\n",
        "# Print the mean and standard deviation\n",
        "print(\"The mean of the errors is: %s.\" % np.mean(scores))\n",
        "print(\"The standard deviation of the errors is: %s.\" % np.std(scores))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean of the errors is: 9.464989603398694.\n",
            "The standard deviation of the errors is: 7.265762094853885.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zeF8_xuIjSy"
      },
      "source": [
        "You have come along way with model validation techniques. The final chapter will wrap up model validation by discussing how to select the best model and give an introduction to parameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3K0SmYk_2ff"
      },
      "source": [
        "## __Connect with Me__ \n",
        "--- \n",
        "[<img align=\"left\" alt=\"codeSTACKr | Twitter\" width=\"40px\" src=\"https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/twitter.svg\" />][twitter] \n",
        "[<img align=\"left\" alt=\"codeSTACKr | LinkedIn\" width=\"40px\" src=\"https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/linkedin.svg\" />][linkedin] \n",
        "[<img align=\"left\" alt=\"codeSTACKr.com\" width=\"40px\" src=\"https://raw.githubusercontent.com/iconic/open-iconic/master/svg/globe.svg\" />][StackExchange AI] \n",
        "[twitter]: https://twitter.com/F4izy \n",
        "--- \n",
        "[linkedin]: https://www.linkedin.com/in/mohd-faizy/ \n",
        "--- \n",
        "[StackExchange AI]: https://mohd-faizy.github.io\n",
        "--- \n",
        "--- \n",
        "--- \n",
        "---"
      ]
    }
  ]
}